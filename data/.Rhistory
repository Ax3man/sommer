ag3$YEARnf <- as.factor(ag3$YEAR)
head(ag3)
ggplot(data=ag3, aes_string(x="DOY", y=response, fill="YEARnf")) +
geom_bar(stat="identity", position=position_dodge())+
facet_wrap(~YEARnf, scales="free_y") +
ggtitle(response) +
# geom_text(aes(label=PRECTOT), vjust=1.6, color="white",
#           position = position_dodge(0.9), size=3.5)+
# scale_fill_brewer(palette="Paired")+
theme_minimal()
ggplot(data=ag3, aes_string(x="DOY", y=response, fill="YEARnf")) +
geom_bar(stat="identity", position=position_dodge())+
# facet_wrap(~YEARnf, scales="free_y") +
ggtitle(response) +
# geom_text(aes(label=PRECTOT), vjust=1.6, color="white",
#           position = position_dodge(0.9), size=3.5)+
# scale_fill_brewer(palette="Paired")+
theme_minimal()
head(ag3)
ggplot(data=ag3, aes_string(x="DOY", y=response, fill="YEARnf")) +
geom_bar(stat="identity", position=position_dodge())+
facet_wrap(~YEARnf, scales="free_y") +
ggtitle(response) +
# geom_text(aes(label=PRECTOT), vjust=1.6, color="white",
#           position = position_dodge(0.9), size=3.5)+
# scale_fill_brewer(palette="Paired")+
theme_minimal()
library(sommer)
?mmer
?sommer
data(DT_example)
DT <- DT_example
head(DT)
####=========================================####
#### Univariate homogeneous variance models  ####
####=========================================####
## Compound simmetry (CS) model
ans1 <- mmer(Yield~Env,
random= ~ Name + Env:Name,
rcov= ~ units,
data=DT)
summary(ans1)
ans2 <- mmer(Yield~Env,
random= ~Name + vs(ds(Env),Name),
rcov= ~ vs(ds(Env),units),
data=DT)
ans1$monitor
ans1$percChange
ans1$sigmaVector
ans1$dL
ans1$dL2
data("DT_halfdiallel")
DT <- DT_halfdiallel
head(DT)
DT$femalef <- as.factor(DT$female)
DT$malef <- as.factor(DT$male)
DT$genof <- as.factor(DT$geno)
A <- diag(7); colnames(A) <- rownames(A) <- 1:7;A # if you want to provide a covariance matrix
#### model using overlay
modh <- mmer(sugar~1,
random=~vs(overlay(femalef,malef), Gu=A)
+ genof,
data=DT)
?gvs
data(DT_cpdata)
DT <- DT_cpdata
GT <- GT_cpdata
MP <- MP_cpdata
DT$Yield <- imputev(DT$Yield)
#### create the variance-covariance matrix
K <- A.mat(GT) # additive relationship matrix
determinant(K,logarithm = TRUE)$modulus
determinant(solve(K),logarithm = TRUE)$modulus
source('~/Desktop/sommer Extra/AI_mme4.R')
data(DT_example)
DT <- DT_example
# DT <- droplevels(DT[which(DT$Env %in% c("CA.2011","CA.2012")),])#_example
A <- A_example
head(DT)
determinant(A,logarithm = TRUE)$modulus
data(DT_polyploid)
DT <- DT_polyploid
GT <- GT_polyploid
MP <- MP_polyploid
####=========================================####
####### convert markers to numeric format
####=========================================####
numo <- atcg1234(data=GT, ploidy=4);
numo$M[1:5,1:5];
numo$ref.allele[,1:5]
###=========================================####
###### plants with both genotypes and phenotypes
###=========================================####
common <- intersect(DT$Name,rownames(numo$M))
###=========================================####
### get the markers and phenotypes for such inds
###=========================================####
marks <- numo$M[common,]; marks[1:5,1:5]
DT2 <- DT[match(common,DT$Name),];
DT2 <- as.data.frame(DT2)
DT2[1:5,]
###=========================================####
###### Additive relationship matrix, specify ploidy
###=========================================####
K <- A.mat(marks)
determinant(K,logarithm = TRUE)$modulus
determinant(solve(K),logarithm = TRUE)$modulus
K <- K + diag(1e-3, nrow(K))
determinant(K,logarithm = TRUE)$modulus
determinant(solve(K),logarithm = TRUE)$modulus
library(AlphaSimR)
?runMacs2
setwd("/Volumes/COVA-USB/CLASSES TAKEN/2015 SPRING/Hort875 Genetic Analysis R/week10 F1 recombination")
data <- as.matrix(read.table("F1sim_alleledose.txt",header=T,sep="\t",as.is=T,row.names=1))
#303 markers on the rows, 2 parents then 100 progeny in the columns
#assign segregation code to each marker
#BC,F2,NS = not segregating
m <- nrow(data)
mark.type <- rep("NS",m) #initialize to NS
P1.P2 <- paste(data[,"P1"],data[,"P2"],sep=".")
head(P1.P2)
BC <- c("0.1","1.0","1.2","2.1")  #these are BC segregation types
F2 <- c("1.1")
mark.type[which(is.element(P1.P2,BC))] <- "BC"
mark.type[which(is.element(P1.P2,F2))] <- "F2"
mark.type
table(mark.type)  #look at counts for each type
#eliminate NS marks
data2 <- data[which(mark.type!="NS"),]
m2 <- nrow(data2)
mark.type2 <- mark.type[which(mark.type!="NS")]
mark.type2
source("recomb_calc_F1.R")
#demonstrate F2 x F2 calculation
ix.F2 <- which(mark.type2=="F2")
for (i in 1:20) {  #look at nearby loci
print(recomb_freq(data2[ix.F2[i],],data2[ix.F2[i+1],]))
}  # r ~ 0.01
ix.F2
ix.F2[i]
data2[ix.F2[i],]
data2[ix.F2[i+1],]
recomb_freq(data2[ix.F2[i],],data2[ix.F2[i+1],])
for (i in 1:10) { # more distant loci
print(recomb_freq(data2[ix.F2[i],],data2[ix.F2[i+10],]))
}  # r ~ 0.15
data <- as.matrix(read.table("F1sim_alleledose.txt",header=T,sep="\t",as.is=T,row.names=1))
#303 markers on the rows, 2 parents then 100 progeny in the columns
#assign segregation code to each marker
#BC,F2,NS = not segregating
m <- nrow(data)
mark.type <- rep("NS",m) #initialize to NS
P1.P2 <- paste(data[,"P1"],data[,"P2"],sep=".")
head(P1.P2)
data
head(P1.P2)
BC <- c("0.1","1.0","1.2","2.1")  #these are BC segregation types
F2 <- c("1.1")
mark.type[which(is.element(P1.P2,BC))] <- "BC"
mark.type[which(is.element(P1.P2,F2))] <- "F2"
table(mark.type)  #look at counts for each type
#eliminate NS marks
data2 <- data[which(mark.type!="NS"),]
m2 <- nrow(data2)
mark.type2 <- mark.type[which(mark.type!="NS")]
source("recomb_calc_F1.R")
#demonstrate F2 x F2 calculation
ix.F2 <- which(mark.type2=="F2")
for (i in 1:20) {  #look at nearby loci
print(recomb_freq(data2[ix.F2[i],],data2[ix.F2[i+1],]))
}  # r ~ 0.01
for (i in 1:10) { # more distant loci
print(recomb_freq(data2[ix.F2[i],],data2[ix.F2[i+10],]))
}  # r ~ 0.15
i=1
print(recomb_freq(data2[ix.F2[i],],data2[ix.F2[i+50],]))
#three-locus analysis
data <- as.matrix(read.table("F2sim_haldane.txt",header=T,sep="\t",as.is=T,row.names=1)[,-1])
#three-locus analysis
# data <- as.matrix(read.table("F2sim_haldane.txt",header=T,sep="\t",as.is=T,row.names=1)[,-1])
data <- as.matrix(read.table("F2sim_alleledose.txt",header=T,sep="\t",as.is=T,row.names=1)[,-1])
setwd("/Volumes/COVA-USB/CLASSES TAKEN/2015 SPRING/Hort875 Genetic Analysis R/week9 F2-BC recombination")
#three-locus analysis
# data <- as.matrix(read.table("F2sim_haldane.txt",header=T,sep="\t",as.is=T,row.names=1)[,-1])
data <- as.matrix(read.table("F2sim_alleledose.txt",header=T,sep="\t",as.is=T,row.names=1)[,-1])
#data <- as.matrix(read.table("F2sim_kosambi.txt",header=T,sep="\t",as.is=T,row.names=1)[,-1])
source("recomb_calc.R")  #load function for F2 pop analysis
#calculate r matrix for F2 population (same as before)
m <- nrow(data)
rmat <- matrix(NA,m,m)
diag(rmat) <- rep(0,m)
for (i in 1:(m-2)) {
mark_i <- data[i,]
result <- apply(data[(i+1):m,],1,recomb_calc,mark_i)
rmat[i,(i+1):m] <- result[1,]
}
result <- recomb_calc(data[m-1,],data[m,])  #handle last case separately
rmat[m-1,m] <- result[1]
# complete symmetric r and LOD matrices
rmat[lower.tri(rmat)] <- t(rmat)[lower.tri(t(rmat))]
rmat[1:5,1:%]
rmat[1:5,1:5]
n.pt <- 100
u <- rep(0,n.pt)
v <- rep(0,n.pt)
w <- rep(0,n.pt)
for (k in 1:n.pt) {
trio <- sort(sample(1:101,3))  #random trio of markers from chrom A
r13 <- rmat[trio[1],trio[3]]
r12 <- rmat[trio[1],trio[2]]
r23 <- rmat[trio[2],trio[3]]
u[k] <- r13
v[k] <- r12+r23
w[k] <- r12*r23
}
plot(u,v,xlab="r13",ylab="r12+r23")
lines(c(0,0.5),c(0,0.5))  #shows that recombination frequency is not additive, deviations increase as markers get farther apart
lm.ans <- summary(lm(y~x-1,data.frame(y=u-v,x=-2*w)))  #Crossover interference
print(Interference <- 1-lm.ans$coefficients[1,1])
data <- as.matrix(read.table("F2sim_alleledose.txt",sep="\t",header=T,row.names=1)[,-1])
#first column was F1 parent
#simulated F2 data, N=100, 3 chromosomes (A,B,C), each with 101 evenly spaced markers, total chrom length = 50 cM
data[1:10,1:10]
dim(data)
m <- nrow(data)
rmat <- matrix(NA,m,m)
rmat2 <- matrix(NA,m,m)
LODmat <- matrix(NA,m,m)
diag(rmat) <- rep(Inf,m)
for (i in 1:(m-2)) { #for each marker
mark_i <- data[i,]
# recomb of all marks against my marker "i"
result <- apply(data[(i+1):m,],1,recomb_calc,mark_i)
rmat[i,(i+1):m] <- result[1,] #row 1 is stored in the matrix for recombinations
LODmat[i,(i+1):m] <- result[2,] #row 2 is stored in the LOD matrix
rmat2[i,(i+1):m] <- apply(data[(i+1):m,],1,rc2,mark_i)	# recombination using the shortcut approach that don't use MLE
}
# same than inside the loop but for the last case
result <- recomb_calc(data[m-1,],data[m,])  #handle last case separately
rmat[m-1,m] <- result[1]
LODmat[m-1,m] <- result[2]
rmat2[m-1,m] <- rc2(data[m-1,],data[m,])
# complete symmetric r and LOD matrices by using lower.tri and upper.tri functions
LODmat[lower.tri(LODmat)] <- t(LODmat)[lower.tri(t(LODmat))]
rmat[lower.tri(rmat)] <- t(rmat)[lower.tri(t(rmat))]
# plotting results
plot(rmat[1,],ylab="Recomb Freq with Marker A0",col=c(rep("blue",101),rep("red",101),rep("black",101))) #101 markers per chrom
legend("bottomright",legend=c("Chrom A","Chrom B","Chrom C"),col=c("blue","red","black"),lty=rep(1,3))
# combining the 2 methods in a single matrix to compare both methods
rmat_compare <- rmat
rmat_compare[lower.tri(rmat_compare)] <- t(rmat2)[lower.tri(t(rmat2))]
image(rmat_compare,xaxt="n",yaxt="n",main="recomb_freq")
# how do they compare
plot(rmat,rmat2,xlab="Full ML estimator",ylab="Approx ML Estimator")
lines(c(0,0.5),c(0,0.5),col="red")  #Approx ML estimator appears upwardly biased
#use hclust with recomb freq
rownames(rmat) <- rownames(data)
clust.ans <- hclust(as.dist(rmat),method="single")
plot(clust.ans,cex=0.01,hang=0,ylab="Recomb Freq")  # three chromosomes are clearly separated
#use hclust with LOD
expLOD <- exp(-LODmat)  #need to create dissimilarity matrix
rownames(expLOD) <- rownames(data)
clust.ans <- hclust(as.dist(expLOD),method="single")
clust2 <- clust.ans
maxLOD <- max(setdiff(LODmat,Inf))
clust2$height <- ifelse(clust.ans$height>0,-log(clust.ans$height),maxLOD)
plot(clust2,cex=0.01,hang=0,ylab="LOD",xlab="",main="")
# Make LGs
LGs <- cutree(clust.ans,h=exp(-3))  #use LOD = 3 cutoff
tapply(LGs,factor(LGs),length)  #3 chroms, each with 101 markers
# assume we have a variable binomially distributed
# we take a sample 100 and 43 made rebudding
n=100
j=43
# we create the likelihood function, a function that is just the pdf for binomial
binlikelihood <- function (j,n,p){
y <- dbinom(x=j,size=n,prob=p,log=T) #log=T uses log-likelihood instead of just likelihood
return(y)
}
# we get the MLE for the parameter "p" given we observed "n" and "j"
pmax <- optimize(binlikelihood,interval=c(0,1),j=43, n=100,maximum=T)
pmax[1]  # the MLE is j/n
# let see t graphically
p1 <- seq(from=0.2, to=.8, by=0.01) # make up data, random values
L <- binlikelihood(n=100,j=43,p=p1) # calculate likelihood for the make up data
plot(p1,L) # plot the likelihoods for different values of p
abline(v=pmax[1], col="blue", lw=2) # line at MLE
rm(list=ls())
# likelihood function or pdf or density function
normlikelihood <- function (thetahat,mean1,sd1){
y <- dnorm(x=thetahat,mean=mean1,sd=sd1)
return(y)
}
# suppose the real mean is 10 in the population
# we take a sample of 10 individuals
x <- rnorm(10,10,2) # made up sample
(Xbar <- mean(x)) # we calculate the average Xbar
(sdhat <- sd(x)) # it's std deviation
pmax <- optimize(normlikelihood,interval=c(1,20),thetahat=Xbar,sd=sdhat,maximum=T)
pmax
# if we want to see te results graphically
# we use the x values, single measurements as possible means
xmup <- seq(1,20,by=0.1) # made up values to see which maximezes the L
L <- normlikelihood(thetahat=xmup,mean1=Xbar,sd1=sdhat)
plot(xmup,L)
abline(v=pmax[1], col="blue", lw=2)
rm(list=ls())
# likelihood function or pdf or density function
poissonlik <- function (x,lambda1){
y <- dpois(x,lambda=lambda1)
return(y)
}
# suppose the real mean is 10 in the population
# we take a sample of 10 individuals
x <- rpois(n=100,lambda=2) # made up values to see which maximezes the L
lambda=2
# now we want to find the MLE of miu, the mean, we will see that the MLE
# of miu is in fact Xbar
xbar <- round(mean(x))
pmax <- optimize(poissonlik,interval=c(0,6),x=xbar,maximum=T)
pmax
fx <- poissonlik(x,2)
plot(x,fx)
abline(v=pmax[1], col="blue", lw=2)
rm(list=ls())
# likelihood function or pdf or density function
explik <- function (x,rate1){
y <- dexp(x,rate=rate1)
return(y)
}
# suppose the real mean is 10 in the population
# we take a sample of 10 individuals
x <- rexp(n=100,rate=1) # made up values to see which maximezes the L
bounds = c(1e-09,1e+09)
xbar <- mean(x)
# now we want to find the MLE of lambda, the mean, we will see that the MLE
# of lambda is...
# using the mean value of x to find the MLE
pmax <- optimize(explik,interval=c(min(x),max(x)),x=xbar,maximum=T)
pmax
fx <- explik(x,1)
plot(x,fx,main="Exponential Distribution")
abline(v=pmax[1], col="blue", lw=2)
6000/.7
8571*12
(8571*12)*1.2
library(sommer)
?DT_sleepstudy
data(DT_sleepstudy)
DT <- DT_sleepstudy
head(DT)
##################################
## lme4
# fm1 <- lmer(Reaction ~ Days + (1 | Subject), data=DT)
# vc <- VarCorr(fm1); print(vc,comp=c("Variance"))
## sommer
fm2 <- mmer(Reaction ~ Days,
random= ~ Subject,
data=DT, tolparinv = 1e-6, verbose = FALSE)
summary(fm2)$varcomp
##################################
## lme4
# fm1 <- lmer(Reaction ~ Days + (1 | Subject), data=DT)
# vc <- VarCorr(fm1); print(vc,comp=c("Variance"))
## sommer
library(orthopolynom)
fm2 <- mmer(Reaction ~ Days,
random= ~ vs(us(leg(Subject))),
data=DT, tolparinv = 1e-6, verbose = FALSE)
fm2 <- mmer(Reaction ~ Days,
random= ~ vs(us(leg(Days)), Subject),
data=DT, tolparinv = 1e-6, verbose = FALSE)
fm2 <- mmer(Reaction ~ Days,
random= ~ vs(us(leg(Days)), Subject),
data=DT, tolparinv = 1e-6, verbose = TRUE)
summary(fm2)$varcomp
pp <- predict.mmer(fm2, classify = c("Days","Subject"))
source('~/Desktop/sommer/R/FUN_vsgvs.R')
fm2 <- mmer(Reaction ~ Days,
random= ~ vs(us(leg(Days)), Subject),
data=DT, tolparinv = 1e-6, verbose = TRUE)
summary(fm2)$varcomp
pp <- predict.mmer(fm2, classify = c("Days","Subject"))
head(pp$pvals)
?DT_cpdata
data(DT_cpdata)
DT <- DT_cpdata
GT <- GT_cpdata
MP <- MP_cpdata
#### create the variance-covariance matrix
A <- A.mat(GT) # additive relationship matrix
#### look at the data and fit the model
head(DT)
mix1 <- mmer(Yield~1,
random=~vs(id,Gu=A)
+ Rowf + Colf,
rcov=~units,
data=DT)
summary(mix1)$varcomp
pp <- predict(mix1,classify = "u:id")
pp <- predict(mix1,classify = "id")
head(pp$pvals)
?DT_expdesigns
data(DT_expdesigns)
DT <- DT_expdesigns
names(DT)
data1 <- DT$au1
head(data1)
## response variable: "yield"
## check indicator: "entryc" ('nc' for all unreplicated, but personal.name for checks)
## blocking factor: "block"
## treatments, personal names for replicated and non-replicated: "trt"
## check no check indicator: "new"
mix1 <- mmer(yield~entryc,
random=~block+trt,
rcov=~units,
data=data1)
summary(mix1)
pp <- predict.mmer(mix1, classify = "entryc")
head(pp$pvals)
pp <- predict.mmer(mix1, classify = "block")
head(pp$pvals)
source('~/Desktop/sommer/R/FUN_vsgvs.R')
?DT_mohring
data(DT_mohring)
DT <- DT_mohring
head(DT)
DT2 <- add.diallel.vars(DT,par1="Par1", par2="Par2")
head(DT2)
# GRIFFING MODEL 2 with reciprocal effects ###########################
mod1h <- mmer(Ftime ~ 1, data=DT2,
random = ~ Block
# GCA male & female overlayed
+ overlay(Par1, Par2)
# SCA effects (includes cross and selfs)
+ cross.id
# SCAR reciprocal effects (if zero there's no reciprocal effects)
+ cross.id:cross.type)
summary(mod1h)$varcomp
pp <- predict(mod1h, classify = "Block")
# GRIFFING MODEL 2 with reciprocal effects ###########################
mod1h <- mmer(Ftime ~ 1, data=DT2,
random = ~ Block
# GCA male & female overlayed
+ vs(overlay(Par1, Par2) )
# SCA effects (includes cross and selfs)
+ cross.id
# SCAR reciprocal effects (if zero there's no reciprocal effects)
+ cross.id:cross.type)
summary(mod1h)$varcomp
pp <- predict(mod1h, classify = "Block")
head(pp$pvals)
pp <- predict(mod1h, classify = "Par1")
head(pp$pvals)
data(DT_example)
DT <- DT_example
# DT <- droplevels(DT[which(DT$Env %in% c("CA.2011","CA.2012")),])#_example
A <- A_example
head(DT)
DT$Yield2 <- scale(DT$Yield)
ans1 <- mmer(Yield~Env,
random= ~vs(ds(Env),Name), reshape.output = T,
rcov= ~ vs(ds(Env),units), iters=19,
data=DT)
ans2 <- mmer(Yield2~Env,
random= ~vs(ds(Env),Name), reshape.output = F,
rcov= ~ vs(ds(Env),units), iters=1,
data=DT)
ans3 <- mmer(Yield2~Env,
random= ~vs(us(Env),Name),
rcov= ~ vs(ds(Env),units), iters=1, return.param = TRUE,
data=DT)
ans4 <- mmer(Yield2~Env,
random= ~vs(ds(Env),Name), reshape.output = T,
rcov= ~ vs(ds(Env),units), iters=1,
data=DT)
ans5 <- mmer(Yield~Env,
random= ~vs(ds(Env),Name), reshape.output = T,
rcov= ~ vs(ds(Env),units), iters=1,
data=DT)
ansx <- mmer(Yield~Env,
random= ~vs(ds(Env),Name),
rcov= ~ vs(ds(Env),units), iters=100,
data=DT)
library(devtools)
devtools::install_github("ropensci/nasapower",force = TRUE) # aug 2021
install.packages("devtools")
library(EnvRtype)
## Temperature for a single location:
# tepic 21.5003, -104.8619
dat1 <- get_weather(env.id = "NM", lat = 21.5003, lon = -104.8619, # lat = 19.5242, lon = -98.8122,
start.day = "2000-01-01", end.day = "2020-12-30",
variables.names = c("T2M","T2M_MAX","T2M_MIN","PRECTOT", "WS2M","RH2M","T2MDEW", "ALLSKY_SFC_LW_DWN", "ALLSKY_SFC_SW_DWN"))
?prod
prod
load("~/Desktop/sommer/data/DT_technow.RData")
library(sommer)
?DT_technow
load("~/Desktop/sommer/data/DT_polyploid.RData")
head(GT_polyploid)
load("~/Desktop/sommer/data/DT_technow.RData")
setwd("~/Desktop/sommer/data")
save(DT_technow,Md_technow,Mf_technow,file = "DT_technow.RData")
dim(Md)
dim(Md_technow)
Md_technow[1:5,1:5]
hist(Md_technow)
hist(Mf_technow)
?build.HMM
library(sommer)
?mmer
?sommer
