y <- dnorm(x=thetahat,mean=mean1,sd=sd1)
return(y)
}
# suppose the real mean is 10 in the population
# we take a sample of 10 individuals
x <- rnorm(10,10,2) # made up sample
(Xbar <- mean(x)) # we calculate the average Xbar
(sdhat <- sd(x)) # it's std deviation
pmax <- optimize(normlikelihood,interval=c(1,20),thetahat=Xbar,sd=sdhat,maximum=T)
pmax
# if we want to see te results graphically
# we use the x values, single measurements as possible means
xmup <- seq(1,20,by=0.1) # made up values to see which maximezes the L
L <- normlikelihood(thetahat=xmup,mean1=Xbar,sd1=sdhat)
plot(xmup,L)
abline(v=pmax[1], col="blue", lw=2)
rm(list=ls())
# likelihood function or pdf or density function
poissonlik <- function (x,lambda1){
y <- dpois(x,lambda=lambda1)
return(y)
}
# suppose the real mean is 10 in the population
# we take a sample of 10 individuals
x <- rpois(n=100,lambda=2) # made up values to see which maximezes the L
lambda=2
# now we want to find the MLE of miu, the mean, we will see that the MLE
# of miu is in fact Xbar
xbar <- round(mean(x))
pmax <- optimize(poissonlik,interval=c(0,6),x=xbar,maximum=T)
pmax
fx <- poissonlik(x,2)
plot(x,fx)
abline(v=pmax[1], col="blue", lw=2)
rm(list=ls())
# likelihood function or pdf or density function
explik <- function (x,rate1){
y <- dexp(x,rate=rate1)
return(y)
}
# suppose the real mean is 10 in the population
# we take a sample of 10 individuals
x <- rexp(n=100,rate=1) # made up values to see which maximezes the L
bounds = c(1e-09,1e+09)
xbar <- mean(x)
# now we want to find the MLE of lambda, the mean, we will see that the MLE
# of lambda is...
# using the mean value of x to find the MLE
pmax <- optimize(explik,interval=c(min(x),max(x)),x=xbar,maximum=T)
pmax
fx <- explik(x,1)
plot(x,fx,main="Exponential Distribution")
abline(v=pmax[1], col="blue", lw=2)
6000/.7
8571*12
(8571*12)*1.2
library(sommer)
?DT_sleepstudy
data(DT_sleepstudy)
DT <- DT_sleepstudy
head(DT)
##################################
## lme4
# fm1 <- lmer(Reaction ~ Days + (1 | Subject), data=DT)
# vc <- VarCorr(fm1); print(vc,comp=c("Variance"))
## sommer
fm2 <- mmer(Reaction ~ Days,
random= ~ Subject,
data=DT, tolparinv = 1e-6, verbose = FALSE)
summary(fm2)$varcomp
##################################
## lme4
# fm1 <- lmer(Reaction ~ Days + (1 | Subject), data=DT)
# vc <- VarCorr(fm1); print(vc,comp=c("Variance"))
## sommer
library(orthopolynom)
fm2 <- mmer(Reaction ~ Days,
random= ~ vs(us(leg(Subject))),
data=DT, tolparinv = 1e-6, verbose = FALSE)
fm2 <- mmer(Reaction ~ Days,
random= ~ vs(us(leg(Days)), Subject),
data=DT, tolparinv = 1e-6, verbose = FALSE)
fm2 <- mmer(Reaction ~ Days,
random= ~ vs(us(leg(Days)), Subject),
data=DT, tolparinv = 1e-6, verbose = TRUE)
summary(fm2)$varcomp
pp <- predict.mmer(fm2, classify = c("Days","Subject"))
source('~/Desktop/sommer/R/FUN_vsgvs.R')
fm2 <- mmer(Reaction ~ Days,
random= ~ vs(us(leg(Days)), Subject),
data=DT, tolparinv = 1e-6, verbose = TRUE)
summary(fm2)$varcomp
pp <- predict.mmer(fm2, classify = c("Days","Subject"))
head(pp$pvals)
?DT_cpdata
data(DT_cpdata)
DT <- DT_cpdata
GT <- GT_cpdata
MP <- MP_cpdata
#### create the variance-covariance matrix
A <- A.mat(GT) # additive relationship matrix
#### look at the data and fit the model
head(DT)
mix1 <- mmer(Yield~1,
random=~vs(id,Gu=A)
+ Rowf + Colf,
rcov=~units,
data=DT)
summary(mix1)$varcomp
pp <- predict(mix1,classify = "u:id")
pp <- predict(mix1,classify = "id")
head(pp$pvals)
?DT_expdesigns
data(DT_expdesigns)
DT <- DT_expdesigns
names(DT)
data1 <- DT$au1
head(data1)
## response variable: "yield"
## check indicator: "entryc" ('nc' for all unreplicated, but personal.name for checks)
## blocking factor: "block"
## treatments, personal names for replicated and non-replicated: "trt"
## check no check indicator: "new"
mix1 <- mmer(yield~entryc,
random=~block+trt,
rcov=~units,
data=data1)
summary(mix1)
pp <- predict.mmer(mix1, classify = "entryc")
head(pp$pvals)
pp <- predict.mmer(mix1, classify = "block")
head(pp$pvals)
source('~/Desktop/sommer/R/FUN_vsgvs.R')
?DT_mohring
data(DT_mohring)
DT <- DT_mohring
head(DT)
DT2 <- add.diallel.vars(DT,par1="Par1", par2="Par2")
head(DT2)
# GRIFFING MODEL 2 with reciprocal effects ###########################
mod1h <- mmer(Ftime ~ 1, data=DT2,
random = ~ Block
# GCA male & female overlayed
+ overlay(Par1, Par2)
# SCA effects (includes cross and selfs)
+ cross.id
# SCAR reciprocal effects (if zero there's no reciprocal effects)
+ cross.id:cross.type)
summary(mod1h)$varcomp
pp <- predict(mod1h, classify = "Block")
# GRIFFING MODEL 2 with reciprocal effects ###########################
mod1h <- mmer(Ftime ~ 1, data=DT2,
random = ~ Block
# GCA male & female overlayed
+ vs(overlay(Par1, Par2) )
# SCA effects (includes cross and selfs)
+ cross.id
# SCAR reciprocal effects (if zero there's no reciprocal effects)
+ cross.id:cross.type)
summary(mod1h)$varcomp
pp <- predict(mod1h, classify = "Block")
head(pp$pvals)
pp <- predict(mod1h, classify = "Par1")
head(pp$pvals)
data(DT_example)
DT <- DT_example
# DT <- droplevels(DT[which(DT$Env %in% c("CA.2011","CA.2012")),])#_example
A <- A_example
head(DT)
DT$Yield2 <- scale(DT$Yield)
ans1 <- mmer(Yield~Env,
random= ~vs(ds(Env),Name), reshape.output = T,
rcov= ~ vs(ds(Env),units), iters=19,
data=DT)
ans2 <- mmer(Yield2~Env,
random= ~vs(ds(Env),Name), reshape.output = F,
rcov= ~ vs(ds(Env),units), iters=1,
data=DT)
ans3 <- mmer(Yield2~Env,
random= ~vs(us(Env),Name),
rcov= ~ vs(ds(Env),units), iters=1, return.param = TRUE,
data=DT)
ans4 <- mmer(Yield2~Env,
random= ~vs(ds(Env),Name), reshape.output = T,
rcov= ~ vs(ds(Env),units), iters=1,
data=DT)
ans5 <- mmer(Yield~Env,
random= ~vs(ds(Env),Name), reshape.output = T,
rcov= ~ vs(ds(Env),units), iters=1,
data=DT)
ansx <- mmer(Yield~Env,
random= ~vs(ds(Env),Name),
rcov= ~ vs(ds(Env),units), iters=100,
data=DT)
library(devtools)
devtools::install_github("ropensci/nasapower",force = TRUE) # aug 2021
install.packages("devtools")
library(EnvRtype)
## Temperature for a single location:
# tepic 21.5003, -104.8619
dat1 <- get_weather(env.id = "NM", lat = 21.5003, lon = -104.8619, # lat = 19.5242, lon = -98.8122,
start.day = "2000-01-01", end.day = "2020-12-30",
variables.names = c("T2M","T2M_MAX","T2M_MIN","PRECTOT", "WS2M","RH2M","T2MDEW", "ALLSKY_SFC_LW_DWN", "ALLSKY_SFC_SW_DWN"))
?prod
prod
?warning
colsdropped=2
warning(paste("fixed-effect model matrix is rank deficient so dropping",colsdropped,"columns / coefficients\n"),call. = FALSE)
library(sommer)
data("DT_cpdata")
mix <- mmer(Yield~1, random = ~ id + spl2Db(Row,Col), rcov=~units, data=DT, date.warning = FALSE)
?DT_cpdata
DT <- DT_cpdata
GT <- GT_cpdata
MP <- MP_cpdata
mix <- mmer(Yield~1, random = ~ id + spl2Db(Row,Col), rcov=~units, data=DT, date.warning = FALSE)
temp <- predict.mmer(object = mix, classify = "id", date.warning = FALSE)
mix <- mmer(Yield~1, random = ~ id + vs(spl2Db(Row,Col)), rcov=~units, data=DT, date.warning = FALSE)
?spl2Da
mix <- mmer(Yield~1, random = ~ id + vs(spl2Da(Row,Col)), rcov=~units, data=DT, date.warning = FALSE)
mix <- mmer(Yield~1, random = ~ id + spl2Da(Row,Col), rcov=~units, data=DT, date.warning = FALSE)
mix <- mmer(Yield~1, random = ~ id + spl2Db(Row,Col), rcov=~units, data=DT, date.warning = FALSE)
summary(mix)$varcomp
?spl2Db
library(TPSbits)
citation("TPSbits")
library(sommer)
data("DT_cpdata")
DT <- DT_cpdata
GT <- GT_cpdata
MP <- MP_cpdata
mix <- mmer(Yield~1, random = ~ id + spl2Db(Row,Col), rcov=~units, data=DT, date.warning = FALSE)
xx <- with(DT,spl2Db(Row,Col))
str(xx)
xx <- with(DT,spl2Da(Row,Col))
str(xx)
mix <- mmer(Yield~1, random = ~ id , rcov=~units, data=DT, date.warning = FALSE)
temp <- predict.mmer(object = mix, classify = "id", date.warning = FALSE)
mix <- mmer(Yield~1, random = ~ id + spl2Db(Row,Col), rcov=~units, data=DT, date.warning = FALSE)
temp <- predict.mmer(object = mix, classify = "id", date.warning = FALSE)
source('~/Desktop/sommer/R/predict.R')
temp <- predict.mmer(object = mix, classify = "id", date.warning = FALSE)
source('~/Desktop/sommer/R/predict.R')
source('~/Desktop/sommer/R/predict.R')
temp <- predict.mmer(object = mix, classify = "id", date.warning = FALSE)
source('~/Desktop/sommer/R/predict.R')
source('~/Desktop/sommer/R/predict.R')
temp <- predict.mmer(object = mix, classify = "id", date.warning = FALSE)
object = mix
classify = "id"
classify<- unique(unlist(strsplit(classify,":")))
classify
if(is.null(classify)){
stop("Please provide the classify argument. For fitted values use the fitted() function.",call. = FALSE)
}
oto <- oto2 <- object$terms
object$terms
oto2$fixed[[1]] <- setdiff(oto2$fixed[[1]],c("1","-1"))
oto2$fixed <- lapply(oto2$fixed,function(x){paste(x,collapse = ":")})
oto2$random <- lapply(oto2$random,function(x){paste(x,collapse = ":")}) # paste to present as A:B:C
oto2$fixed
oto2$random
for(u in 3:length(object$terms)){ # change random terms to split by ":"
prov <- object$terms[[u]]
if(length(prov) > 0){
for(v in 1:length(prov)){
object$terms[[u]][[v]] <- unlist(strsplit(prov[[v]],":"))
}
}
}
object$terms
# This doesn't quite give identical results. Does it matter?
include <- unique(c(attr(terms.formula(object$call$fixed), "term.labels"),attr(terms.formula(object$call$random), "term.labels"))) # paste to present as A:B:C
include
# This doesn't quite give identical results. Does it matter?
all.vars(object$call$fixed)
all.vars(object$call$random)
# This doesn't quite give identical results. Does it matter?
unique(c(all.vars(object$call$fixed),all.vars(object$call$random)))
# This doesn't quite give identical results. Does it matter?
include <- unique(c(all.vars(object$call$fixed),all.vars(object$call$random)))
# include <- unique(c(attr(terms.formula(object$call$fixed), "term.labels"),attr(terms.formula(object$call$random), "term.labels"))) # paste to present as A:B:C
include <- setdiff(include, c("1","-1"))
include
##################################################
# step 0. find all variables used in the modeling
allTermsUsed <- unique(c(unlist(object$terms$fixed), unlist(object$terms$random)))
allTermsUsed
# Remove 1 and -1 terms
allTermsUsed <- allTermsUsed[which(!allTermsUsed %in% c("1", "-1"))]
# reformulate turns a character vector into a formula object so that the terms can be pulled out
allTermsUsed <- unique(attr(terms.formula(reformulate(allTermsUsed)), "term.labels")) # paste to present as A:B:C
allTermsUsed
allTermsUsed
# Remove terms that include a : (i.e. interaction terms)
allTermsUsed <- allTermsUsed[!grepl(":", allTermsUsed)]
allTermsUsed
# all.vars(form)
toAgg <- unique(unlist(strsplit(include,":")))
toAgg
ignored <- setdiff(allTermsUsed,toAgg)
ignored
attr(terms.formula(object$call$fixed), "term.labels")
object$call$fixed
attr(terms.formula(object$call$fixed), "term.labels")
all.vars(object$call$fixed)
object$call$fixed
all.vars(as.formula("y~1+x"))
all.vars(object$call$fixed)[-1]
all.vars(object$call$fixed)
# This doesn't quite give identical results. Does it matter?
include <- unique(c(all.vars(object$call$fixed)[-1], # variables in the fixed formula (remove the response)
all.vars(object$call$random))) # variables in the random formula
# include <- unique(c(attr(terms.formula(object$call$fixed), "term.labels"),attr(terms.formula(object$call$random), "term.labels"))) # paste to present as A:B:C
include <- setdiff(include, c("1","-1"))
##################################################
# step 0. find all variables used in the modeling
allTermsUsed <- unique(c(unlist(object$terms$fixed), unlist(object$terms$random)))
# Remove 1 and -1 terms
allTermsUsed <- allTermsUsed[which(!allTermsUsed %in% c("1", "-1"))]
# reformulate turns a character vector into a formula object so that the terms can be pulled out
allTermsUsed <- unique(attr(terms.formula(reformulate(allTermsUsed)), "term.labels")) # paste to present as A:B:C
# Remove terms that include a : (i.e. interaction terms)
allTermsUsed <- allTermsUsed[!grepl(":", allTermsUsed)]
allTermsUsed
# all.vars(form)
toAgg <- unique(unlist(strsplit(include,":")))
toAgg
ignored <- setdiff(allTermsUsed,toAgg)
ignored
classify
allTermsUsed
toAgg
# print(head(object$dataOriginal))
# print(toAgg)
levelsOfTerms <- lapply(as.list(toAgg),function(x){(unique(object$dataOriginal[,x]))})
levelsOfTerms
unlist(object$terms$fixed)
unlist(object$terms$random)
source('~/Desktop/sommer/R/predict.R')
temp <- predict.mmer(object = mix, classify = "id", date.warning = FALSE)
temp$hypertable
?predict.mmer
oto <- oto2 <- object$terms
oto2$fixed[[1]] <- setdiff(oto2$fixed[[1]],c("1","-1")) # get fixed factors plus intercept
oto2$fixed <- lapply(oto2$fixed,function(x){paste(x,collapse = ":")}) # paste the fixed factors
oto2$random <- lapply(oto2$random,function(x){paste(x,collapse = ":")}) # paste the random terms
oto2$random
for(u in 3:length(object$terms)){ # change random terms to split by ":"
prov <- object$terms[[u]]
if(length(prov) > 0){
for(v in 1:length(prov)){
object$terms[[u]][[v]] <- unlist(strsplit(prov[[v]],":"))
}
}
}
# initially assume that we will include all the factors in the prediction
include <- setdiff(unique(c(unlist(object$terms$fixed),unlist(object$terms$random))),c("1","-1"))
include
source('~/Desktop/sommer/R/predict.R')
?DT_augment
data(DT_augment)
DT <- DT_augment
head(DT)
####=========================================####
#### fit the mixed model and check summary
####=========================================####
mix1 <- mmer(TSW ~ Check.Gen,
random = ~ Block + Genotype:Check,
data=DT)
summary(mix1)$varcomp
temp <- predict(mix1, classify = "Block")
temp$hypertable
hyp <- temp$hypertable
hyp$include[1:2]<-F
hyp$ignored[1:2]<-T
hyp
temp2 <- predict(mix1, classify = "Block", hypertable = hyp)
temp <- predict(mix1, classify = "Block")
temp <- predict(mix1, classify = "Block")
head(temp$pvals)
install.packages("~/Desktop/sommer_4.1.6.tar.gz", repos = NULL, type = "source")
library(sommer)
data("DT_cpdata")
data(DT_augment)
DT <- DT_augment
head(DT)
####=========================================####
#### fit the mixed model and check summary
####=========================================####
mix1 <- mmer(TSW ~ Check.Gen,
random = ~ Block + Genotype:Check,
data=DT)
summary(mix1)$varcomp
temp <- predict(mix1, classify = "Block")
head(temp$pvals)
library(crayon)
?`crayon-package`
packageStartupMessage(blue(paste("[]==================================================================[]")),appendLF=TRUE)
packageStartupMessage(yellow(paste("[]==================================================================[]")),appendLF=TRUE)
packageStartupMessage(magenta(paste("[]==================================================================[]")),appendLF=TRUE)
data(DT_cpdata)
DT <- DT_cpdata
GT <- GT_cpdata
MP <- MP_cpdata
#### create the variance-covariance matrix
A <- A.mat(GT) # additive relationship matrix
n <- nrow(DT) # to be used for degrees of freedom
k <- 1 # to be used for degrees of freedom (number of levels in fixed effects)
###########################
#### Regular GWAS/EMMAX approach
###########################
mix2 <- GWAS(color~1,
random=~vs(id, Gu=A) + Rowf + Colf,
rcov=~units, M=GT, gTerm = "u:id",
verbose = FALSE, iters=3,
data=DT)
###########################
#### GWAS by RRBLUP approach
###########################
Z <- GT[as.character(DT$id),]
mixRRBLUP <- mmer(color~1,
random=~vs(Z) + Rowf + Colf,
rcov=~units, iters=3,
verbose = FALSE,
data=DT)
a <- mixRRBLUP$U$`u:Z`$color # marker effects
se.a <- sqrt(diag(kronecker(diag(ncol(Z)),mixRRBLUP$sigma$`u:Z`) - mixRRBLUP$PevU$`u:Z`$color)) # SE of marker effects
t.stat <- a/se.a # t-statistic
pvalRRBLUP <- dt(t.stat,df=n-k-1) # -log10(pval)
###########################
#### GWAS by GBLUP approach
###########################
M<- GT
MMT <-tcrossprod(M) ## MM' = additive relationship matrix
MMTinv<-solve(MMT) ## inverse of MM'
MTMMTinv<-t(M)%*%MMTinv # M' %*% (M'M)-
mixGBLUP <- mmer(color~1,
random=~vs(id, Gu=MMT) + Rowf + Colf,
rcov=~units, iters=3,
verbose = FALSE,
data=DT)
a.from.g <-MTMMTinv%*%matrix(mixGBLUP$U$`u:id`$color,ncol=1)
var.g <- kronecker(MMT,mixGBLUP$sigma$`u:id`) - mixGBLUP$PevU$`u:id`$color
var.a.from.g <- t(M)%*%MMTinv%*% (var.g) %*% t(MMTinv)%*%M
se.a.from.g <- sqrt(diag(var.a.from.g))
t.stat.from.g <- a.from.g/se.a.from.g # t-statistic
pvalGBLUP <- dt(t.stat.from.g,df=n-k-1) # -log10(pval)
plot(mix2$scores[,1], main="GWAS")
plot(-log(pvalRRBLUP), main="GWAS by RRBLUP/SNP-BLUP")
plot(-log(pvalGBLUP), main="GWAS by GBLUP")
plot(mix2$scores[,1], main="GWAS")
plot(-log(pvalRRBLUP), main="GWAS by RRBLUP/SNP-BLUP")
plot(-log(pvalGBLUP), main="GWAS by GBLUP")
# setwd("~/Desktop/sommer/vignettes")
setwd("~/Desktop/sommer/vignettes")
library(rmarkdown)
library(sommer)
# Sys.which("pdflatex")
# Sys.getenv("PATH")
# Sys.setenv(PATH=paste(Sys.getenv("PATH"),"/usr/texbin",sep=":"))
render("v1.sommer.quick.start.Rmd", pdf_document())
render("v2.sommer.changes.and.faqs.Rmd", pdf_document())
render("v3.sommer.qg.Rmd", pdf_document())
render("v4.sommer.gxe.Rmd", pdf_document())
render("v5.sommer.vs.lme4.Rmd", pdf_document())
render("v6.sommer.spatial.Rmd", pdf_document())
install.packages("~/Desktop/sommer_4.1.6.tar.gz", repos = NULL, type = "source")
install.packages("~/Desktop/sommer_4.1.6.tar.gz", repos = NULL, type = "source")
library(sommer)
?summary.mmer
library(gremlin)
?`gremlin-package`
?gremlin
ai
?ai
?gremlin
grSire <- gremlin(WWG11 ~ sex, random = ~ sire, data = Mrode11)
head(Mrode11)
dim(Mrode11)
# Now drop sire random effects and use the `anova` method to compare models
grLM <- update(grSire, random = ~ 1)  #<-- use `~1` to drop all random effects
anova(grSire, grLM)
# Modular functions
## get model matrices for a mixed model
mM11 <- mkModMats(WWG11 ~ sex - 1, random = ~ sire, data = Mrode11)
mM11
## setup model, but do not evaluate the log-likelihood
grSetup <- gremlinSetup(WWG11 ~ sex - 1, random = ~ sire, data = Mrode11)
grSetup
gremlinSetup
## maximize the restricted maximum likelihood
grOut <- remlIt(grSetup)
remlIt
summary(grOut)
Ainv <- makeAinv(Mrode11[, 1:3])$Ainv
## Not run:
# Following the example from Mrode 2005, chapter 11.
library(nadiv)  #<-- to construct inverse of the numerator relatedness matrix
Ainv <- makeAinv(Mrode11[, 1:3])$Ainv
gr11lmm <- gremlin(WWG11 ~ sex - 1,
random = ~ calf,
data = Mrode11,
ginverse = list(calf = Ainv),
Gstart = matrix(0.2), Rstart = matrix(0.4),  #<-- specify starting values
maxit = 15,    #<-- maximum iterations
v = 2, vit = 1,  #<-- moderate screen output (`v`) every iteration (`vit`)
algit = "AI")  #<-- only use Average Information algorithm iterations
## Not run:
# Following the example from Mrode 2005, chapter 11.
library(nadiv)  #<-- to construct inverse of the numerator relatedness matrix
Ainv <- makeAinv(Mrode11[, 1:3])$Ainv
